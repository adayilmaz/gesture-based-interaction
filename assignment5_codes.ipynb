{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q1hJcrtQbYOs"
   },
   "source": [
    "# HAND GESTURE-BASED INTERACTION\n",
    "\n",
    "---\n",
    "\n",
    "Group members:\n",
    "*   Ada Yılmaz\n",
    "*   Ceren Şahin\n",
    "*   Sima Adleyba\n",
    "*   Selen Naz Gürsoy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RAjfOu8vbX9T"
   },
   "source": [
    "### Installing necessary libraries and models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XUn2JcSgZ7Q7",
    "outputId": "9c342d67-09a3-467c-8af2-efcfc6585f03"
   },
   "outputs": [],
   "source": [
    "#install mediapipe\n",
    "%pip install -q mediapipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KtyLGHBsaCoN"
   },
   "outputs": [],
   "source": [
    "#download a model that can recognize 7 hand gestures: 👍, 👎, ✌️, ☝️, ✊, 👋, 🤟\n",
    "!wget -q https://storage.googleapis.com/mediapipe-models/gesture_recognizer/gesture_recognizer/float16/1/gesture_recognizer.task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "j03y4pVScZr5"
   },
   "outputs": [],
   "source": [
    "#download test images from pixabay\n",
    "import urllib\n",
    "\n",
    "IMAGE_FILENAMES = ['thumbs_down.jpg', 'victory.jpg', 'thumbs_up.jpg', 'pointing_up.jpg']\n",
    "\n",
    "for name in IMAGE_FILENAMES:\n",
    "  url = f'https://storage.googleapis.com/mediapipe-tasks/gesture_recognizer/{name}'\n",
    "  urllib.request.urlretrieve(url, name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a_QNcKXCdAuq"
   },
   "outputs": [],
   "source": [
    "#or we can use our own images as shown below\n",
    "\n",
    "# from google.colab import files\n",
    "# uploaded = files.upload()\n",
    "\n",
    "# for filename in uploaded:\n",
    "#   content = uploaded[filename]\n",
    "#   with open(filename, 'wb') as f:\n",
    "#     f.write(content)\n",
    "# IMAGE_FILENAMES = list(uploaded.keys())\n",
    "\n",
    "# print('Uploaded files:', IMAGE_FILENAMES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5WqLvhGEczPc"
   },
   "source": [
    "### Functions for visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-10T15:23:11.250747Z",
     "start_time": "2024-12-10T15:23:09.667380Z"
    }
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import mediapipe as mp\n",
    "from mediapipe.framework.formats import landmark_pb2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "eZQdCS6uaRny",
    "ExecuteTime": {
     "end_time": "2024-12-10T15:23:11.284606Z",
     "start_time": "2024-12-10T15:23:11.254421Z"
    }
   },
   "outputs": [],
   "source": [
    "#some functions to visualize the gesture recognition results.\n",
    "import math\n",
    "\n",
    "plt.rcParams.update({\n",
    "    'axes.spines.top': False,\n",
    "    'axes.spines.right': False,\n",
    "    'axes.spines.left': False,\n",
    "    'axes.spines.bottom': False,\n",
    "    'xtick.labelbottom': False,\n",
    "    'xtick.bottom': False,\n",
    "    'ytick.labelleft': False,\n",
    "    'ytick.left': False,\n",
    "    'xtick.labeltop': False,\n",
    "    'xtick.top': False,\n",
    "    'ytick.labelright': False,\n",
    "    'ytick.right': False\n",
    "})\n",
    "\n",
    "mp_hands = mp.solutions.hands\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_drawing_styles = mp.solutions.drawing_styles\n",
    "\n",
    "\n",
    "def display_one_image(image, title, subplot, titlesize=16):\n",
    "    \"\"\"Displays one image along with the predicted category name and score.\"\"\"\n",
    "    plt.subplot(*subplot)\n",
    "    plt.imshow(image)\n",
    "    if len(title) > 0:\n",
    "        plt.title(title, fontsize=int(titlesize), color='black', fontdict={'verticalalignment':'center'}, pad=int(titlesize/1.5))\n",
    "    return (subplot[0], subplot[1], subplot[2]+1)\n",
    "\n",
    "\n",
    "def display_batch_of_images_with_gestures_and_hand_landmarks(images, results):\n",
    "    \"\"\"Displays a batch of images with the gesture category and its score along with the hand landmarks.\"\"\"\n",
    "    # Images and labels.\n",
    "    images = [image.numpy_view() for image in images]\n",
    "    gestures = [top_gesture for (top_gesture, _) in results]\n",
    "    multi_hand_landmarks_list = [multi_hand_landmarks for (_, multi_hand_landmarks) in results]\n",
    "\n",
    "    # Auto-squaring: this will drop data that does not fit into square or square-ish rectangle.\n",
    "    rows = int(math.sqrt(len(images)))\n",
    "    cols = len(images) // rows\n",
    "\n",
    "    # Size and spacing.\n",
    "    FIGSIZE = 13.0\n",
    "    SPACING = 0.1\n",
    "    subplot=(rows,cols, 1)\n",
    "    if rows < cols:\n",
    "        plt.figure(figsize=(FIGSIZE,FIGSIZE/cols*rows))\n",
    "    else:\n",
    "        plt.figure(figsize=(FIGSIZE/rows*cols,FIGSIZE))\n",
    "\n",
    "    # Display gestures and hand landmarks.\n",
    "    for i, (image, gestures) in enumerate(zip(images[:rows*cols], gestures[:rows*cols])):\n",
    "        title = f\"{gestures.category_name} ({gestures.score:.2f})\"\n",
    "        dynamic_titlesize = FIGSIZE*SPACING/max(rows,cols) * 40 + 3\n",
    "        annotated_image = image.copy()\n",
    "\n",
    "        for hand_landmarks in multi_hand_landmarks_list[i]:\n",
    "          hand_landmarks_proto = landmark_pb2.NormalizedLandmarkList()\n",
    "          hand_landmarks_proto.landmark.extend([\n",
    "            landmark_pb2.NormalizedLandmark(x=landmark.x, y=landmark.y, z=landmark.z) for landmark in hand_landmarks\n",
    "          ])\n",
    "\n",
    "          mp_drawing.draw_landmarks(\n",
    "            annotated_image,\n",
    "            hand_landmarks_proto,\n",
    "            mp_hands.HAND_CONNECTIONS,\n",
    "            mp_drawing_styles.get_default_hand_landmarks_style(),\n",
    "            mp_drawing_styles.get_default_hand_connections_style())\n",
    "\n",
    "        subplot = display_one_image(annotated_image, title, subplot, titlesize=dynamic_titlesize)\n",
    "\n",
    "    # Layout.\n",
    "    plt.tight_layout()\n",
    "    plt.subplots_adjust(wspace=SPACING, hspace=SPACING)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AnVjzQPedaun"
   },
   "source": [
    "### Preview the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "m9uzHARZddDK",
    "outputId": "42c11584-885e-4a08-ee4c-a81189d64573",
    "ExecuteTime": {
     "end_time": "2024-12-10T15:23:11.693865Z",
     "start_time": "2024-12-10T15:23:11.266014Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'IMAGE_FILENAMES' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[3], line 20\u001B[0m\n\u001B[1;32m     17\u001B[0m     cv2\u001B[38;5;241m.\u001B[39mdestroyAllWindows()  \u001B[38;5;66;03m# Close the window after key press\u001B[39;00m\n\u001B[1;32m     19\u001B[0m \u001B[38;5;66;03m# Example usage\u001B[39;00m\n\u001B[0;32m---> 20\u001B[0m images \u001B[38;5;241m=\u001B[39m {name: cv2\u001B[38;5;241m.\u001B[39mimread(name) \u001B[38;5;28;01mfor\u001B[39;00m name \u001B[38;5;129;01min\u001B[39;00m \u001B[43mIMAGE_FILENAMES\u001B[49m}\n\u001B[1;32m     22\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m name, image \u001B[38;5;129;01min\u001B[39;00m images\u001B[38;5;241m.\u001B[39mitems():\n\u001B[1;32m     23\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m image \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "\u001B[0;31mNameError\u001B[0m: name 'IMAGE_FILENAMES' is not defined"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import math\n",
    "\n",
    "DESIRED_HEIGHT = 480\n",
    "DESIRED_WIDTH = 480\n",
    "\n",
    "def resize_and_show(image, name):\n",
    "    h, w = image.shape[:2]\n",
    "    if h < w:\n",
    "        img = cv2.resize(image, (DESIRED_WIDTH, math.floor(h / (w / DESIRED_WIDTH))))\n",
    "    else:\n",
    "        img = cv2.resize(image, (math.floor(w / (h / DESIRED_HEIGHT)), DESIRED_HEIGHT))\n",
    "    \n",
    "    # Display the image in a window with a name\n",
    "    cv2.imshow(name, img)\n",
    "    cv2.waitKey(0)  # Wait for a key press to close the window\n",
    "    cv2.destroyAllWindows()  # Close the window after key press\n",
    "\n",
    "# Example usage\n",
    "images = {name: cv2.imread(name) for name in IMAGE_FILENAMES}\n",
    "\n",
    "for name, image in images.items():\n",
    "    if image is not None:\n",
    "        print(f\"Displaying: {name}\")\n",
    "        resize_and_show(image, name)\n",
    "    else:\n",
    "        print(f\"Error: Could not read image {name}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0zRNOZm7d5Wr"
   },
   "source": [
    "### Google implementation - do not run\n",
    "This first one is a how to from google, we can create our own by following the steps given.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "JwAdQ_VjeAku",
    "outputId": "f8982a23-7eff-456b-b915-af0daf1ec27f",
    "ExecuteTime": {
     "end_time": "2024-12-10T15:23:11.702980Z",
     "start_time": "2024-12-10T15:23:11.695369Z"
    }
   },
   "outputs": [],
   "source": [
    "# STEP 1: Import the necessary modules.\n",
    "import mediapipe as mp\n",
    "from mediapipe.tasks import python\n",
    "from mediapipe.tasks.python import vision\n",
    "\n",
    "# STEP 2: Create an GestureRecognizer object.\n",
    "base_options = python.BaseOptions(model_asset_path='gesture_recognizer.task')\n",
    "options = vision.GestureRecognizerOptions(base_options=base_options)\n",
    "recognizer = vision.GestureRecognizer.create_from_options(options)\n",
    "\n",
    "images = []\n",
    "results = []\n",
    "for image_file_name in IMAGE_FILENAMES:\n",
    "    \n",
    "  # STEP 3: Load the input image.\n",
    "  image = mp.Image.create_from_file(image_file_name)\n",
    "\n",
    "  # STEP 4: Recognize gestures in the input image.\n",
    "  recognition_result = recognizer.recognize(image)\n",
    "\n",
    "  # STEP 5: Process the result. In this case, visualize it.\n",
    "  images.append(image)\n",
    "  top_gesture = recognition_result.gestures[0][0]\n",
    "  hand_landmarks = recognition_result.hand_landmarks\n",
    "  results.append((top_gesture, hand_landmarks))\n",
    "\n",
    "display_batch_of_images_with_gestures_and_hand_landmarks(images, results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Example - do not run\n",
    "Tried an example to see how it works and update the functions accordingly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vxV_DPPWeBOo",
    "ExecuteTime": {
     "start_time": "2024-12-10T15:23:11.700700Z"
    }
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "\n",
    "# Initialize MediaPipe Hands\n",
    "mp_hands = mp.solutions.hands\n",
    "hands = mp_hands.Hands()\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "# Initialize webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "def detect_peace_sign(hand_landmarks):\n",
    "    # Get coordinates of relevant landmarks\n",
    "    index_tip = hand_landmarks.landmark[mp_hands.HandLandmark.INDEX_FINGER_TIP]\n",
    "    middle_tip = hand_landmarks.landmark[mp_hands.HandLandmark.MIDDLE_FINGER_TIP]\n",
    "    ring_tip = hand_landmarks.landmark[mp_hands.HandLandmark.RING_FINGER_TIP]\n",
    "    pinky_tip = hand_landmarks.landmark[mp_hands.HandLandmark.PINKY_TIP]\n",
    "    \n",
    "    \n",
    "    index_mcp = hand_landmarks.landmark[mp_hands.HandLandmark.INDEX_FINGER_MCP]\n",
    "    middle_mcp = hand_landmarks.landmark[mp_hands.HandLandmark.MIDDLE_FINGER_MCP]\n",
    "    ring_mcp = hand_landmarks.landmark[mp_hands.HandLandmark.RING_FINGER_MCP]\n",
    "    pinky_mcp = hand_landmarks.landmark[mp_hands.HandLandmark.PINKY_MCP]\n",
    "\n",
    "\n",
    "    # Define peace sign gesture: index and middle fingers up, ring and pinky fingers down\n",
    "    if (\n",
    "        # Index and middle fingers' tips must be highest parts of those fingers\n",
    "        (index_tip.y < index_mcp.y) and (middle_tip.y < middle_mcp.y)\n",
    "        and\n",
    "        # Index finger's tips must be higher than other fingers' mcp\n",
    "        (index_tip.y < ring_mcp.y) and (index_tip.y < pinky_mcp.y)\n",
    "        and\n",
    "        # Middle finger's tips must be higher than other fingers' mcp\n",
    "        (middle_tip.y < ring_mcp.y) and (middle_tip.y < pinky_mcp.y)\n",
    "    ):\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Convert the frame to RGB\n",
    "    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Process the frame and detect hands\n",
    "    result = hands.process(frame_rgb)\n",
    "\n",
    "    if result.multi_hand_landmarks:\n",
    "        for hand_landmarks in result.multi_hand_landmarks:\n",
    "            # Draw hand landmarks\n",
    "            mp_drawing.draw_landmarks(frame, hand_landmarks, mp_hands.HAND_CONNECTIONS)\n",
    "\n",
    "            # Detect custom gesture (peace sign)\n",
    "            if detect_peace_sign(hand_landmarks):\n",
    "                cv2.putText(frame, 'Peace Sign Detected!', (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2, cv2.LINE_AA)\n",
    "                # Trigger interaction (e.g., print a message)\n",
    "                print(\"Peace sign gesture detected!\")\n",
    "\n",
    "    # Display the frame\n",
    "    cv2.imshow('MediaPipe Hands', frame)\n",
    "\n",
    "    if cv2.waitKey(5) & 0xFF == 27:\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Gesture Detection Functions\n",
    "After checking how the upper ones worked, we implemented fixed, more robust versions of gesture detection functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-10T15:23:11.732729Z",
     "start_time": "2024-12-10T15:23:11.704500Z"
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# Global variables for tracking gestures and cooldown\n",
    "\n",
    "# The currently detected gesture\n",
    "current_gesture = None\n",
    "\n",
    "# Time when the current gesture expires\n",
    "gesture_reset_time = 0\n",
    "\n",
    "# Cooldown variables for scrolling\n",
    "previous_thumb_tip = None\n",
    "previous_index_tip = None\n",
    "last_gesture_time = 0\n",
    "COOLDOWN_PERIOD = 1.5\n",
    "\n",
    "# Reset current gesture when it expires\n",
    "def reset_gesture():\n",
    "    global current_gesture, gesture_reset_time\n",
    "    if time.time() > gesture_reset_time:\n",
    "        current_gesture = None\n",
    "\n",
    "# Gesture detection functions\n",
    "def detect_peace_sign(hand_landmarks):\n",
    "    \n",
    "    # Track the time of the last detected gesture\n",
    "    global last_gesture_time\n",
    "\n",
    "    # Get landmarks\n",
    "    index_tip = hand_landmarks.landmark[mp_hands.HandLandmark.INDEX_FINGER_TIP]\n",
    "    middle_tip = hand_landmarks.landmark[mp_hands.HandLandmark.MIDDLE_FINGER_TIP]\n",
    "    ring_tip = hand_landmarks.landmark[mp_hands.HandLandmark.RING_FINGER_TIP]\n",
    "    pinky_tip = hand_landmarks.landmark[mp_hands.HandLandmark.PINKY_TIP]\n",
    "\n",
    "    index_mcp = hand_landmarks.landmark[mp_hands.HandLandmark.INDEX_FINGER_MCP]\n",
    "    middle_mcp = hand_landmarks.landmark[mp_hands.HandLandmark.MIDDLE_FINGER_MCP]\n",
    "    ring_mcp = hand_landmarks.landmark[mp_hands.HandLandmark.RING_FINGER_MCP]\n",
    "    pinky_mcp = hand_landmarks.landmark[mp_hands.HandLandmark.PINKY_MCP]\n",
    "\n",
    "    # Check that index and middle are raised above their MCPs and other MCPs\n",
    "    index_and_middle_up = (\n",
    "        (index_tip.y < index_mcp.y) and\n",
    "        (middle_tip.y < middle_mcp.y) and\n",
    "        (index_tip.y < ring_mcp.y) and \n",
    "        (index_tip.y < pinky_mcp.y) and\n",
    "        (middle_tip.y < ring_mcp.y) and \n",
    "        (middle_tip.y < pinky_mcp.y)\n",
    "    )\n",
    "\n",
    "    # Check spacing between index and middle fingers\n",
    "    index_middle_spacing = abs(index_tip.x - middle_tip.x) > 0.1\n",
    "\n",
    "    # Check that ring and pinky are down (their tips should be below their MCP joints)\n",
    "    ring_and_pinky_down = (\n",
    "        (ring_tip.y > ring_mcp.y + 0.02) and\n",
    "        (pinky_tip.y > pinky_mcp.y + 0.02)\n",
    "    )\n",
    "\n",
    "    if index_and_middle_up and index_middle_spacing and ring_and_pinky_down:\n",
    "        \n",
    "        # Update last gesture time (to apply cooldown for peace sign gesture)\n",
    "        last_gesture_time = time.time()\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "\n",
    "\n",
    "def detect_thumbs_up(hand_landmarks, margin=0.05):\n",
    "    \n",
    "    # Track the time of the last detected gesture\n",
    "    global last_gesture_time \n",
    "\n",
    "    # Get landmarks\n",
    "    index_tip = hand_landmarks.landmark[mp_hands.HandLandmark.INDEX_FINGER_TIP]\n",
    "    middle_tip = hand_landmarks.landmark[mp_hands.HandLandmark.MIDDLE_FINGER_TIP]\n",
    "    ring_tip = hand_landmarks.landmark[mp_hands.HandLandmark.RING_FINGER_TIP]\n",
    "    pinky_tip = hand_landmarks.landmark[mp_hands.HandLandmark.PINKY_TIP]\n",
    "    thumb_tip = hand_landmarks.landmark[mp_hands.HandLandmark.THUMB_TIP]\n",
    "\n",
    "    index_mcp = hand_landmarks.landmark[mp_hands.HandLandmark.INDEX_FINGER_MCP]\n",
    "    middle_mcp = hand_landmarks.landmark[mp_hands.HandLandmark.MIDDLE_FINGER_MCP]\n",
    "    ring_mcp = hand_landmarks.landmark[mp_hands.HandLandmark.RING_FINGER_MCP]\n",
    "    pinky_mcp = hand_landmarks.landmark[mp_hands.HandLandmark.PINKY_MCP]\n",
    "    thumb_mcp = hand_landmarks.landmark[mp_hands.HandLandmark.THUMB_MCP]\n",
    "    \n",
    "    thumb_base = hand_landmarks.landmark[mp_hands.HandLandmark.THUMB_CMC]\n",
    "\n",
    "    # Thumb tip should be above other fingertips\n",
    "    thumb_tip_up = ((thumb_tip.y + margin < index_tip.y) and\n",
    "                    (thumb_tip.y + margin < middle_tip.y) and\n",
    "                    (thumb_tip.y + margin < ring_tip.y) and\n",
    "                    (thumb_tip.y + margin < pinky_tip.y) and\n",
    "                    (thumb_tip.y < thumb_mcp.y))\n",
    "    \n",
    "    # Other fingers should be in order from top to bottom\n",
    "    other_fingers_ordered = ((index_mcp.y < middle_mcp.y) and\n",
    "                             (middle_mcp.y < ring_mcp.y) and\n",
    "                             (ring_mcp.y < pinky_mcp.y))\n",
    "    \n",
    "    \n",
    "    if thumb_tip_up and other_fingers_ordered:\n",
    "        \n",
    "        # Update last gesture time (to apply cooldown for thumbs-up gesture)\n",
    "        last_gesture_time = time.time()\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "\n",
    "def detect_thumbs_down(hand_landmarks, margin=0.05):\n",
    "    \n",
    "    # Track the time of the last detected gesture\n",
    "    global last_gesture_time\n",
    "\n",
    "    # Get landmarks\n",
    "    index_tip = hand_landmarks.landmark[mp_hands.HandLandmark.INDEX_FINGER_TIP]\n",
    "    middle_tip = hand_landmarks.landmark[mp_hands.HandLandmark.MIDDLE_FINGER_TIP]\n",
    "    ring_tip = hand_landmarks.landmark[mp_hands.HandLandmark.RING_FINGER_TIP]\n",
    "    pinky_tip = hand_landmarks.landmark[mp_hands.HandLandmark.PINKY_TIP]\n",
    "    thumb_tip = hand_landmarks.landmark[mp_hands.HandLandmark.THUMB_TIP]\n",
    "\n",
    "    index_mcp = hand_landmarks.landmark[mp_hands.HandLandmark.INDEX_FINGER_MCP]\n",
    "    middle_mcp = hand_landmarks.landmark[mp_hands.HandLandmark.MIDDLE_FINGER_MCP]\n",
    "    ring_mcp = hand_landmarks.landmark[mp_hands.HandLandmark.RING_FINGER_MCP]\n",
    "    pinky_mcp = hand_landmarks.landmark[mp_hands.HandLandmark.PINKY_MCP]\n",
    "\n",
    "    # Thumb tip must be lower than anything else\n",
    "    thumb_tip_down = ((thumb_tip.y > index_tip.y + margin) and\n",
    "                    (thumb_tip.y > middle_tip.y + margin) and\n",
    "                    (thumb_tip.y > ring_tip.y + margin) and\n",
    "                    (thumb_tip.y > pinky_tip.y + margin))\n",
    "    \n",
    "    # Other fingers should be in the order (from top to down) pinky > ring > middle > index finger\n",
    "    other_fingers_ordered = ((index_mcp.y > middle_mcp.y) and\n",
    "                             (middle_mcp.y > ring_mcp.y) and\n",
    "                             (ring_mcp.y > pinky_mcp.y))\n",
    "    \n",
    "    if thumb_tip_down and other_fingers_ordered:\n",
    "        \n",
    "        # Update last gesture time (to apply cooldown for thumbs-down gesture)\n",
    "        last_gesture_time = time.time()\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def detect_scroll(hand_landmarks, threshold=0.1, dominance_ratio=4.0):\n",
    "    \n",
    "    # Get previous positions and last gesture time\n",
    "    global previous_thumb_tip, previous_index_tip, last_gesture_time\n",
    "\n",
    "    # Get current positions\n",
    "    current_thumb_tip_x = hand_landmarks.landmark[mp_hands.HandLandmark.THUMB_TIP].x\n",
    "    current_thumb_tip_y = hand_landmarks.landmark[mp_hands.HandLandmark.THUMB_TIP].y\n",
    "    current_index_tip_x = hand_landmarks.landmark[mp_hands.HandLandmark.INDEX_FINGER_TIP].x\n",
    "    current_index_tip_y = hand_landmarks.landmark[mp_hands.HandLandmark.INDEX_FINGER_TIP].y\n",
    "\n",
    "    # Check for cooldown\n",
    "    current_time = time.time()\n",
    "    \n",
    "    # If last gesture happened not before cooldown, return False (no scroll)\n",
    "    if current_time - last_gesture_time < COOLDOWN_PERIOD:\n",
    "        return False, None \n",
    "\n",
    "    # Initialize previous positions if not set\n",
    "    if previous_thumb_tip is None or previous_index_tip is None:\n",
    "        previous_thumb_tip = (current_thumb_tip_x, current_thumb_tip_y)\n",
    "        previous_index_tip = (current_index_tip_x, current_index_tip_y)\n",
    "        return False, None\n",
    "\n",
    "    # Calculate location changes\n",
    "    thumb_horizontal_disp = current_thumb_tip_x - previous_thumb_tip[0]\n",
    "    thumb_vertical_disp = current_thumb_tip_y - previous_thumb_tip[1]\n",
    "    index_horizontal_disp = current_index_tip_x - previous_index_tip[0]\n",
    "    index_vertical_disp = current_index_tip_y - previous_index_tip[1]\n",
    "\n",
    "    # Average the movements of thumb and index for robustness\n",
    "    horizontal_disp = (thumb_horizontal_disp + index_horizontal_disp) / 2\n",
    "    vertical_disp = (thumb_vertical_disp + index_vertical_disp) / 2\n",
    "\n",
    "    # Determine dominant movement (we want to return only a horizontal or vertical movement)\n",
    "    horizontal_movement = abs(horizontal_disp) > threshold\n",
    "    vertical_movement = abs(vertical_disp) > threshold\n",
    "\n",
    "    # Check dominance\n",
    "    if horizontal_movement and abs(horizontal_disp) > dominance_ratio * abs(vertical_disp):\n",
    "        direction = \"right\" if horizontal_disp > 0 else \"left\"\n",
    "        dominant_axis = \"horizontal\"\n",
    "    elif vertical_movement and abs(vertical_disp) > dominance_ratio * abs(horizontal_disp):\n",
    "        direction = \"down\" if vertical_disp > 0 else \"up\"\n",
    "        dominant_axis = \"vertical\"\n",
    "    else:\n",
    "        direction = None\n",
    "        dominant_axis = None\n",
    "\n",
    "    # If there is a dominant movement\n",
    "    if dominant_axis:\n",
    "        \n",
    "        # Update positions\n",
    "        previous_thumb_tip = (current_thumb_tip_x, current_thumb_tip_y)\n",
    "        previous_index_tip = (current_index_tip_x, current_index_tip_y)\n",
    "        \n",
    "        # Update last gesture time\n",
    "        last_gesture_time = current_time \n",
    "        return True, direction\n",
    "\n",
    "    return False, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-12-10T15:23:11.709789Z"
    }
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "\n",
    "# Initialize MediaPipe Hands\n",
    "mp_hands = mp.solutions.hands\n",
    "hands = mp_hands.Hands(min_detection_confidence=0.7, min_tracking_confidence=0.7)\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "# Initialize webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Global variables for tracking previous positions\n",
    "previous_thumb_tip = None\n",
    "previous_index_tip = None\n",
    "\n",
    "print(\"Press 'Esc' to exit.\")\n",
    "\n",
    "# Initialize gesture display variables\n",
    "current_gesture = None \n",
    "gesture_display_time = 0 \n",
    "GESTURE_DISPLAY_DURATION = 1.5 \n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Flip the frame horizontally\n",
    "    frame = cv2.flip(frame, 1)\n",
    "\n",
    "    # Convert the frame to RGB\n",
    "    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Process the frame and detect hands\n",
    "    result = hands.process(frame_rgb)\n",
    "\n",
    "    if result.multi_hand_landmarks:\n",
    "        for hand_landmarks in result.multi_hand_landmarks:\n",
    "            # Draw hand landmarks\n",
    "            mp_drawing.draw_landmarks(frame, hand_landmarks, mp_hands.HAND_CONNECTIONS)\n",
    "\n",
    "            # Detect gestures\n",
    "            detected_gesture = None\n",
    "            if detect_peace_sign(hand_landmarks):\n",
    "                detected_gesture = \"Peace Sign Detected!\"\n",
    "            elif detect_thumbs_up(hand_landmarks):\n",
    "                detected_gesture = \"Thumbs Up Detected!\"\n",
    "            elif detect_thumbs_down(hand_landmarks):\n",
    "                detected_gesture = \"Thumbs Down Detected!\"\n",
    "            \n",
    "            # If a gesture is detected, update the display variables\n",
    "            if detected_gesture:\n",
    "                current_gesture = detected_gesture\n",
    "                gesture_display_time = time.time()\n",
    "            else:\n",
    "                # Only check for scroll if no other gesture is detected\n",
    "                detected, direction = detect_scroll(hand_landmarks, threshold=0.1, dominance_ratio=4.0)\n",
    "                if detected:\n",
    "                    current_gesture = f\"Scroll Detected: {direction.title()}!\"\n",
    "                    gesture_display_time = time.time()\n",
    "\n",
    "    # Display the current gesture if within the display duration\n",
    "    if current_gesture and (time.time() - gesture_display_time < GESTURE_DISPLAY_DURATION):\n",
    "        cv2.putText(frame, current_gesture, (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2, cv2.LINE_AA)\n",
    "\n",
    "    # Display the frame\n",
    "    cv2.imshow('Gesture Recognition', frame)\n",
    "\n",
    "    # Break the loop when 'Esc' key is pressed\n",
    "    if cv2.waitKey(5) & 0xFF == 27:\n",
    "        break\n",
    "\n",
    "# Release the webcam and close windows\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cursor control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-12-10T15:23:11.712698Z"
    }
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import pyautogui\n",
    "\n",
    "# Initialize MediaPipe Hands\n",
    "mp_hands = mp.solutions.hands\n",
    "hands = mp_hands.Hands(min_detection_confidence=0.7, min_tracking_confidence=0.7)\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "# Get screen dimensions\n",
    "screen_width, screen_height = pyautogui.size()\n",
    "\n",
    "def is_click_gesture(hand_landmarks):\n",
    "    \"\"\"Detect a pinching gesture for a left click.\"\"\"\n",
    "    index_tip = hand_landmarks.landmark[mp_hands.HandLandmark.INDEX_FINGER_TIP]\n",
    "    thumb_tip = hand_landmarks.landmark[mp_hands.HandLandmark.THUMB_TIP]\n",
    "\n",
    "    # Calculate the 3D Euclidean distance between index tip and thumb tip\n",
    "    distance = ((index_tip.x - thumb_tip.x) ** 2 +\n",
    "                (index_tip.y - thumb_tip.y) ** 2 +\n",
    "                (index_tip.z - thumb_tip.z) ** 2) ** 0.5\n",
    "\n",
    "    # Adjust threshold based on typical 3D distances observed\n",
    "    return distance < 0.05\n",
    "\n",
    "\n",
    "# Open webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "print(\"Press 'Esc' to exit.\")\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Flip the frame horizontally for a mirror-like effect\n",
    "    frame = cv2.flip(frame, 1)\n",
    "\n",
    "    # Get frame dimensions\n",
    "    frame_height, frame_width, _ = frame.shape\n",
    "\n",
    "    # Convert the frame to RGB\n",
    "    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Process the frame and detect hands\n",
    "    result = hands.process(frame_rgb)\n",
    "\n",
    "    if result.multi_hand_landmarks:\n",
    "        for hand_landmarks in result.multi_hand_landmarks:\n",
    "            # Draw hand landmarks\n",
    "            mp_drawing.draw_landmarks(frame, hand_landmarks, mp_hands.HAND_CONNECTIONS)\n",
    "\n",
    "            # Get index finger tip coordinates\n",
    "            index_finger_tip = hand_landmarks.landmark[mp_hands.HandLandmark.INDEX_FINGER_TIP]\n",
    "\n",
    "            # Normalize coordinates to screen dimensions\n",
    "            cursor_x = int(index_finger_tip.x * screen_width)\n",
    "            cursor_y = int(index_finger_tip.y * screen_height)\n",
    "\n",
    "            # Move the mouse cursor\n",
    "            pyautogui.moveTo(cursor_x, cursor_y)\n",
    "\n",
    "            # Detect click gesture\n",
    "            if is_click_gesture(hand_landmarks):\n",
    "                pyautogui.click()\n",
    "                cv2.putText(frame, \"Click!\", (10, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "\n",
    "    # Display the frame\n",
    "    cv2.imshow(\"Gesture-Based Cursor Control\", frame)\n",
    "\n",
    "    # Break the loop when 'Esc' key is pressed\n",
    "    if cv2.waitKey(5) & 0xFF == 27:\n",
    "        break\n",
    "\n",
    "# Release the webcam and close windows\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-12-10T15:26:06.399928Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1733844366.579244   19642 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 89.3), renderer: Apple M1\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "W0000 00:00:1733844366.598994   21582 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1733844366.615778   21581 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "2024-12-10 18:26:15.746 Python[1529:19642] +[IMKClient subclass]: chose IMKClient_Legacy\n",
      "2024-12-10 18:26:15.746 Python[1529:19642] +[IMKInputSession subclass]: chose IMKInputSession_Legacy\n",
      "W0000 00:00:1733844379.241659   21578 landmark_projection_calculator.cc:186] Using NORM_RECT without IMAGE_DIMENSIONS is only supported for the square ROI. Provide IMAGE_DIMENSIONS or use PROJECTION_MATRIX.\n",
      "Exception in Tkinter callback\n",
      "Traceback (most recent call last):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/tkinter/__init__.py\", line 1967, in __call__\n",
      "    return self.func(*args)\n",
      "           ^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/tkinter/__init__.py\", line 861, in callit\n",
      "    func(*args)\n",
      "  File \"/var/folders/lm/pxcyxjg51vd581_781wgrjnw0000gn/T/ipykernel_1529/2693456401.py\", line 179, in update_camera_feed\n",
      "    detect_gesture(hand_landmarks)\n",
      "  File \"/var/folders/lm/pxcyxjg51vd581_781wgrjnw0000gn/T/ipykernel_1529/2693456401.py\", line 94, in detect_gesture\n",
      "    reset_gesture()\n",
      "    ^^^^^^^^^^^^^\n",
      "NameError: name 'reset_gesture' is not defined. Did you mean: 'detect_gesture'?\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import tkinter as tk\n",
    "from PIL import Image, ImageTk, ImageDraw, ImageFont\n",
    "import os\n",
    "import time\n",
    "\n",
    "# Initialize MediaPipe Hands\n",
    "mp_hands = mp.solutions.hands\n",
    "hands = mp_hands.Hands(min_detection_confidence=0.7, min_tracking_confidence=0.7)\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "# Initialize the main Tkinter window\n",
    "root = tk.Tk()\n",
    "root.title(\"Gesture-Controlled Instagram Feed\")\n",
    "root.geometry(\"1024x768\")\n",
    "root.configure(bg=\"#f0f0f0\")\n",
    "\n",
    "# Load photos into a list\n",
    "photo_folder = \"Images/\"\n",
    "photo_files = [os.path.join(photo_folder, f) for f in os.listdir(photo_folder) if f.endswith((\".jpg\", \".png\"))]\n",
    "photos = [Image.open(photo).resize((400, 400)) for photo in photo_files]\n",
    "\n",
    "# Create a label to display a single photo\n",
    "photo_label = tk.Label(root, bg=\"#ffffff\", width=400, height=400)\n",
    "photo_label.pack(side=tk.LEFT, padx=10, pady=10)\n",
    "\n",
    "# Feedback label\n",
    "feedback_label = tk.Label(root, text=\"Perform gestures to interact!\", font=(\"Helvetica\", 14), bg=\"#f0f0f0\")\n",
    "feedback_label.pack(side=tk.BOTTOM, pady=20)\n",
    "\n",
    "# Interaction states\n",
    "current_photo_index = 0  # Start with the first photo\n",
    "liked_photos = {}\n",
    "disliked_photos = {}\n",
    "saved_photos = []  # List to store saved photos\n",
    "showing_saved_photos = False  # Track whether we are showing saved photos\n",
    "\n",
    "# Camera feed frame\n",
    "camera_frame = tk.Label(root, bg=\"#000000\", width=500, height=700)\n",
    "camera_frame.pack(side=tk.RIGHT, padx=10, pady=10)\n",
    "\n",
    "# Function to add emoji to photos\n",
    "def add_emoji(photo, emoji):\n",
    "    \"\"\"Add an emoji to the given photo.\"\"\"\n",
    "    img = photo.copy()\n",
    "    draw = ImageDraw.Draw(img)\n",
    "    font = ImageFont.truetype(\"arial.ttf\", 50)  # Ensure you have a compatible font installed\n",
    "    draw.text((150, 150), emoji, fill=\"red\", font=font)\n",
    "    return img\n",
    "\n",
    "# Function to update the displayed photo\n",
    "def update_photo():\n",
    "    \"\"\"Update the currently displayed photo based on the index.\"\"\"\n",
    "    global current_photo_index\n",
    "    if showing_saved_photos:\n",
    "        if len(saved_photos) == 0:\n",
    "            feedback_label.config(text=\"No saved photos available!\")\n",
    "            photo_label.config(image=\"\")\n",
    "            return\n",
    "        if 0 <= current_photo_index < len(saved_photos):\n",
    "            img = ImageTk.PhotoImage(saved_photos[current_photo_index])\n",
    "            photo_label.configure(image=img)\n",
    "            photo_label.img = img  # Keep a reference to avoid garbage collection\n",
    "    else:\n",
    "        if 0 <= current_photo_index < len(photos):\n",
    "            current_photo = photos[current_photo_index]\n",
    "            if current_photo_index in liked_photos:\n",
    "                current_photo = liked_photos[current_photo_index]\n",
    "            elif current_photo_index in disliked_photos:\n",
    "                current_photo = disliked_photos[current_photo_index]\n",
    "            img = ImageTk.PhotoImage(current_photo)\n",
    "            photo_label.configure(image=img)\n",
    "            photo_label.img = img  # Keep a reference to avoid garbage collection\n",
    "\n",
    "# Function to toggle between all photos and saved photos\n",
    "def show_saved_photos():\n",
    "    global showing_saved_photos, current_photo_index\n",
    "    showing_saved_photos = not showing_saved_photos\n",
    "    current_photo_index = 0  # Reset to the first photo\n",
    "    if showing_saved_photos:\n",
    "        feedback_label.config(text=\"Showing Saved Photos 📂\")\n",
    "    else:\n",
    "        feedback_label.config(text=\"Showing All Photos 🌍\")\n",
    "    update_photo()\n",
    "\n",
    "# Gesture Detection Logic\n",
    "# Gesture Detection Logic\n",
    "def detect_gesture(hand_landmarks):\n",
    "    \"\"\"Detect gestures for liking, disliking, saving, scrolling, and clicking.\"\"\"\n",
    "    global current_photo_index, current_gesture, gesture_reset_time, last_gesture_time\n",
    "\n",
    "    # Reset the current gesture if its reset time has passed\n",
    "    reset_gesture()\n",
    "\n",
    "    # Cooldown check to avoid repeated gesture detection within the cooldown period\n",
    "    current_time = time.time()\n",
    "    if current_time - last_gesture_time < COOLDOWN_PERIOD:\n",
    "        return\n",
    "\n",
    "    # Detect gestures\n",
    "    if detect_thumbs_up(hand_landmarks):\n",
    "        current_gesture = \"like\"\n",
    "        gesture_reset_time = time.time() + COOLDOWN_PERIOD\n",
    "        feedback_label.config(text=\"Photo Liked! ❤️\")\n",
    "        if current_photo_index not in liked_photos:\n",
    "            liked_photos[current_photo_index] = add_emoji(photos[current_photo_index], \"❤️\")\n",
    "        update_photo()\n",
    "        return\n",
    "\n",
    "    if detect_thumbs_down(hand_landmarks):\n",
    "        current_gesture = \"dislike\"\n",
    "        gesture_reset_time = time.time() + COOLDOWN_PERIOD\n",
    "        feedback_label.config(text=\"Photo Disliked! 👎\")\n",
    "        if current_photo_index not in disliked_photos:\n",
    "            disliked_photos[current_photo_index] = add_emoji(photos[current_photo_index], \"👎\")\n",
    "        update_photo()\n",
    "        return\n",
    "\n",
    "    if detect_peace_sign(hand_landmarks):\n",
    "        current_gesture = \"save\"\n",
    "        gesture_reset_time = time.time() + COOLDOWN_PERIOD\n",
    "        feedback_label.config(text=\"Photo Saved! ✌️\")\n",
    "        current_photo = photos[current_photo_index]\n",
    "        if current_photo not in saved_photos:\n",
    "            saved_photos.append(current_photo)\n",
    "        return\n",
    "\n",
    "    # Detect scrolling\n",
    "    scroll_detected, scroll_direction = detect_scroll(hand_landmarks)\n",
    "    if scroll_detected:\n",
    "        current_gesture = \"scroll\"\n",
    "        gesture_reset_time = time.time() + COOLDOWN_PERIOD\n",
    "        if scroll_direction == \"up\":\n",
    "            feedback_label.config(text=\"Scrolling Up ⬆️\")\n",
    "            if current_photo_index > 0:\n",
    "                current_photo_index -= 1\n",
    "        elif scroll_direction == \"down\":\n",
    "            feedback_label.config(text=\"Scrolling Down ⬇️\")\n",
    "            if showing_saved_photos:\n",
    "                if current_photo_index < len(saved_photos) - 1:\n",
    "                    current_photo_index += 1\n",
    "            else:\n",
    "                if current_photo_index < len(photos) - 1:\n",
    "                    current_photo_index += 1\n",
    "        update_photo()\n",
    "        return\n",
    "\n",
    "    # No gesture detected\n",
    "    feedback_label.config(text=\"Perform gestures to interact!\")\n",
    "\n",
    "\n",
    "# Open webcam and process gestures\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "def update_camera_feed():\n",
    "    \"\"\"Update the camera feed and process gestures in real-time.\"\"\"\n",
    "    global current_photo_index\n",
    "\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        return\n",
    "\n",
    "    # Flip the frame horizontally for a mirror-like effect\n",
    "    frame = cv2.flip(frame, 1)\n",
    "\n",
    "    # Convert the frame to RGB for MediaPipe\n",
    "    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Process the frame for hand landmarks\n",
    "    results = hands.process(frame_rgb)\n",
    "\n",
    "    if results.multi_hand_landmarks:\n",
    "        for hand_landmarks in results.multi_hand_landmarks:\n",
    "            # Draw hand landmarks on the frame\n",
    "            mp_drawing.draw_landmarks(frame, hand_landmarks, mp_hands.HAND_CONNECTIONS)\n",
    "\n",
    "            # Detect gestures for liking, disliking, saving, scrolling, and clicking\n",
    "            detect_gesture(hand_landmarks)\n",
    "\n",
    "    # Convert the frame to an image for Tkinter\n",
    "    frame_image = Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "    imgtk = ImageTk.PhotoImage(image=frame_image)\n",
    "\n",
    "    # Display the camera feed in the GUI\n",
    "    camera_frame.imgtk = imgtk\n",
    "    camera_frame.configure(image=imgtk)\n",
    "\n",
    "    # Schedule the next frame update\n",
    "    root.after(10, update_camera_feed)\n",
    "\n",
    "# Start with the first photo\n",
    "update_photo()\n",
    "\n",
    "# Add a button to toggle saved photos\n",
    "saved_button = tk.Button(root, text=\"Show Saved Photos\", command=show_saved_photos, font=(\"Helvetica\", 12))\n",
    "saved_button.pack(side=tk.BOTTOM, pady=10)\n",
    "\n",
    "# Start the camera feed\n",
    "update_camera_feed()\n",
    "\n",
    "# Run the Tkinter event loop\n",
    "root.mainloop()\n",
    "\n",
    "# Release the camera\n",
    "cap.release()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instagram layout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2024-12-10T15:23:11.720363Z"
    }
   },
   "outputs": [],
   "source": [
    "import tkinter as tk\n",
    "from PIL import Image, ImageTk\n",
    "import cv2\n",
    "import requests\n",
    "from io import BytesIO\n",
    "\n",
    "class GestureApp:\n",
    "    def __init__(self, root):\n",
    "        self.root = root\n",
    "        self.root.geometry(\"800x600\")\n",
    "        self.root.title(\"Gesture Controlled App\")\n",
    "\n",
    "        # Placeholder image\n",
    "        self.image_index = 0\n",
    "        self.images = self.fetch_images()  # Fetch Instagram images\n",
    "        self.image_label = tk.Label(root)\n",
    "        self.image_label.pack()\n",
    "\n",
    "        # Buttons\n",
    "        self.like_button = tk.Button(root, text=\"Like\", command=self.like_picture)\n",
    "        self.like_button.pack(side=tk.LEFT)\n",
    "\n",
    "        self.dislike_button = tk.Button(root, text=\"Dislike\", command=self.dislike_picture)\n",
    "        self.dislike_button.pack(side=tk.LEFT)\n",
    "\n",
    "        # Camera feed\n",
    "        self.cap = cv2.VideoCapture(0)\n",
    "        self.update_camera_feed()\n",
    "\n",
    "    def fetch_images(self): #FILL IN FUNCTION\n",
    "        images = []\n",
    "        return images\n",
    "\n",
    "    def update_camera_feed(self):\n",
    "        ret, frame = self.cap.read()\n",
    "        if not ret:\n",
    "            print(\"Camera not working!\")\n",
    "            return\n",
    "\n",
    "        frame = cv2.flip(frame, 1)\n",
    "        rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        # Process frame for hand landmarks (not shown here)\n",
    "\n",
    "        # Convert the frame to an image format that Tkinter can use\n",
    "        img = Image.fromarray(rgb_frame)\n",
    "        imgtk = ImageTk.PhotoImage(image=img)\n",
    "        self.image_label.imgtk = imgtk\n",
    "        self.image_label.configure(image=imgtk)\n",
    "\n",
    "        # Call this method again after 10 milliseconds\n",
    "        self.root.after(10, self.update_camera_feed)\n",
    "\n",
    "    def like_picture(self):\n",
    "        print(\"Liked picture\")\n",
    "\n",
    "    def dislike_picture(self):\n",
    "        print(\"Disliked picture\")\n",
    "\n",
    "# Create the Tkinter window and run the app\n",
    "root = tk.Tk()\n",
    "app = GestureApp(root)\n",
    "root.mainloop()"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Instagram-like Interface Attempt"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1733845170.356242   29315 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 89.3), renderer: Apple M1\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "W0000 00:00:1733845170.387841   31408 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1733845170.404376   31408 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "2024-12-10 18:39:36.133 Python[1670:29315] +[IMKClient subclass]: chose IMKClient_Legacy\n",
      "2024-12-10 18:39:36.133 Python[1670:29315] +[IMKInputSession subclass]: chose IMKInputSession_Legacy\n",
      "W0000 00:00:1733845177.476484   31410 landmark_projection_calculator.cc:186] Using NORM_RECT without IMAGE_DIMENSIONS is only supported for the square ROI. Provide IMAGE_DIMENSIONS or use PROJECTION_MATRIX.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in gesture detection: name 'mp_drawing' is not defined\n",
      "Error in gesture detection: name 'mp_drawing' is not defined\n",
      "Error in gesture detection: name 'mp_drawing' is not defined\n",
      "Error in gesture detection: name 'mp_drawing' is not defined\n",
      "Error in gesture detection: name 'mp_drawing' is not defined\n",
      "Error in gesture detection: name 'mp_drawing' is not defined\n",
      "Error in gesture detection: name 'mp_drawing' is not defined\n",
      "Error in gesture detection: name 'mp_drawing' is not defined\n",
      "Error in gesture detection: name 'mp_drawing' is not defined\n",
      "Error in gesture detection: name 'mp_drawing' is not defined\n",
      "Error in gesture detection: name 'mp_drawing' is not defined\n",
      "Error in gesture detection: name 'mp_drawing' is not defined\n",
      "Error in gesture detection: name 'mp_drawing' is not defined\n",
      "Error in gesture detection: name 'mp_drawing' is not defined\n",
      "Error in gesture detection: name 'mp_drawing' is not defined\n",
      "Error in gesture detection: name 'mp_drawing' is not defined\n",
      "Error in gesture detection: name 'mp_drawing' is not defined\n",
      "Error in gesture detection: name 'mp_drawing' is not defined\n",
      "Error in gesture detection: name 'mp_drawing' is not defined\n",
      "Error in gesture detection: name 'mp_drawing' is not defined\n",
      "Error in gesture detection: name 'mp_drawing' is not defined\n",
      "Error in gesture detection: name 'mp_drawing' is not defined\n",
      "Error in gesture detection: name 'mp_drawing' is not defined\n",
      "Error in gesture detection: name 'mp_drawing' is not defined\n",
      "Error in gesture detection: name 'mp_drawing' is not defined\n",
      "Error in gesture detection: name 'mp_drawing' is not defined\n",
      "Error in gesture detection: name 'mp_drawing' is not defined\n",
      "Error in gesture detection: name 'mp_drawing' is not defined\n",
      "Error in gesture detection: name 'mp_drawing' is not defined\n",
      "Error in gesture detection: name 'mp_drawing' is not defined\n",
      "Error in gesture detection: name 'mp_drawing' is not defined\n",
      "Error in gesture detection: name 'mp_drawing' is not defined\n",
      "Error in gesture detection: name 'mp_drawing' is not defined\n",
      "Error in gesture detection: name 'mp_drawing' is not defined\n",
      "Error in gesture detection: name 'mp_drawing' is not defined\n",
      "Error in gesture detection: name 'mp_drawing' is not defined\n",
      "Error in gesture detection: name 'mp_drawing' is not defined\n",
      "Error in gesture detection: name 'mp_drawing' is not defined\n",
      "Error in gesture detection: name 'mp_drawing' is not defined\n",
      "Error in gesture detection: name 'mp_drawing' is not defined\n",
      "Error in gesture detection: name 'mp_drawing' is not defined\n",
      "Error in gesture detection: name 'mp_drawing' is not defined\n",
      "Error in gesture detection: name 'mp_drawing' is not defined\n",
      "Error in gesture detection: name 'mp_drawing' is not defined\n",
      "Error in gesture detection: name 'mp_drawing' is not defined\n",
      "Error in gesture detection: name 'mp_drawing' is not defined\n",
      "Error in gesture detection: name 'mp_drawing' is not defined\n",
      "Error in gesture detection: name 'mp_drawing' is not defined\n",
      "Error in gesture detection: name 'mp_drawing' is not defined\n",
      "Error in gesture detection: name 'mp_drawing' is not defined\n",
      "Error in gesture detection: name 'mp_drawing' is not defined\n",
      "Error in gesture detection: name 'mp_drawing' is not defined\n",
      "Error in gesture detection: name 'mp_drawing' is not defined\n",
      "Error in gesture detection: name 'mp_drawing' is not defined\n",
      "Error in gesture detection: name 'mp_drawing' is not defined\n",
      "Error in gesture detection: name 'mp_drawing' is not defined\n",
      "Error in gesture detection: name 'mp_drawing' is not defined\n",
      "Error in gesture detection: name 'mp_drawing' is not defined\n",
      "Error in gesture detection: name 'mp_drawing' is not defined\n",
      "Error in gesture detection: name 'mp_drawing' is not defined\n",
      "Error in gesture detection: name 'mp_drawing' is not defined\n",
      "Error in gesture detection: name 'mp_drawing' is not defined\n",
      "Error in gesture detection: name 'mp_drawing' is not defined\n",
      "Error in gesture detection: name 'mp_drawing' is not defined\n",
      "Error in gesture detection: name 'mp_drawing' is not defined\n",
      "Error in gesture detection: name 'mp_drawing' is not defined\n",
      "Error in gesture detection: name 'mp_drawing' is not defined\n",
      "Error in gesture detection: name 'mp_drawing' is not defined\n",
      "Error in gesture detection: name 'mp_drawing' is not defined\n",
      "Error in gesture detection: name 'mp_drawing' is not defined\n",
      "Error in gesture detection: name 'mp_drawing' is not defined\n",
      "Error in gesture detection: name 'mp_drawing' is not defined\n",
      "Error in gesture detection: name 'mp_drawing' is not defined\n",
      "Error in gesture detection: name 'mp_drawing' is not defined\n",
      "Error in gesture detection: name 'mp_drawing' is not defined\n",
      "Error in gesture detection: name 'mp_drawing' is not defined\n",
      "Error in gesture detection: name 'mp_drawing' is not defined\n",
      "Error in gesture detection: name 'mp_drawing' is not defined\n",
      "Error in gesture detection: name 'mp_drawing' is not defined\n",
      "Error in gesture detection: name 'mp_drawing' is not defined\n",
      "Error in gesture detection: name 'mp_drawing' is not defined\n",
      "Error in gesture detection: name 'mp_drawing' is not defined\n",
      "Error in gesture detection: name 'mp_drawing' is not defined\n",
      "Error in gesture detection: name 'mp_drawing' is not defined\n",
      "Error in gesture detection: name 'mp_drawing' is not defined\n",
      "Error in gesture detection: name 'mp_drawing' is not defined\n",
      "Error in gesture detection: name 'mp_drawing' is not defined\n",
      "Error in gesture detection: name 'mp_drawing' is not defined\n",
      "Error in gesture detection: name 'mp_drawing' is not defined\n",
      "Error in gesture detection: name 'mp_drawing' is not defined\n",
      "Error in gesture detection: name 'mp_drawing' is not defined\n",
      "Error in gesture detection: name 'mp_drawing' is not defined\n",
      "Error in gesture detection: name 'mp_drawing' is not defined\n",
      "Error in gesture detection: name 'mp_drawing' is not defined\n",
      "Error in gesture detection: name 'mp_drawing' is not defined\n",
      "Error in gesture detection: name 'mp_drawing' is not defined\n",
      "Error in gesture detection: name 'mp_drawing' is not defined\n",
      "Error in gesture detection: name 'mp_drawing' is not defined\n",
      "Error in gesture detection: name 'mp_drawing' is not defined\n",
      "Error in gesture detection: name 'mp_drawing' is not defined\n",
      "Error in gesture detection: name 'mp_drawing' is not defined\n",
      "Error in gesture detection: name 'mp_drawing' is not defined\n",
      "Error in gesture detection: name 'mp_drawing' is not defined\n",
      "Error in gesture detection: name 'mp_drawing' is not defined\n",
      "Error in gesture detection: name 'mp_drawing' is not defined\n",
      "Error in gesture detection: name 'mp_drawing' is not defined\n",
      "Error in gesture detection: name 'mp_drawing' is not defined\n",
      "Error in gesture detection: name 'mp_drawing' is not defined\n",
      "Error in gesture detection: name 'mp_drawing' is not defined\n",
      "Error in gesture detection: name 'mp_drawing' is not defined\n"
     ]
    }
   ],
   "source": [
    "import tkinter as tk\n",
    "from PIL import Image, ImageTk\n",
    "import os\n",
    "import cv2\n",
    "import random\n",
    "import mediapipe as mp\n",
    "import time\n",
    "\n",
    "# Initialize MediaPipe Hands\n",
    "mp_hands = mp.solutions.hands\n",
    "hands = mp_hands.Hands(\n",
    "    static_image_mode=False,  # Dynamic mode is faster\n",
    "    max_num_hands=1,  # Detect only one hand to reduce processing\n",
    "    min_detection_confidence=0.5,  # Slightly lower confidence threshold\n",
    "    min_tracking_confidence=0.5\n",
    ")\n",
    "\n",
    "# Initialize Tkinter\n",
    "root = tk.Tk()\n",
    "root.geometry(\"1024x768\")\n",
    "root.title(\"Gesture-Controlled Instagram\")\n",
    "\n",
    "# Load Images\n",
    "photo_folder = \"Images/\"  # Replace with your folder path\n",
    "photo_files = [os.path.join(photo_folder, f) for f in os.listdir(photo_folder) if f.endswith((\".jpg\", \".png\"))]\n",
    "photos = [Image.open(photo).resize((400, 400)) for photo in photo_files]\n",
    "random.shuffle(photos)  # Shuffle photos for randomness\n",
    "\n",
    "# Initialize State\n",
    "current_photo_index = 0\n",
    "liked_photos = set()  # To store liked photo indices\n",
    "disliked_photos = set()  # To store disliked photo indices\n",
    "\n",
    "# Display Area\n",
    "photo_label = tk.Label(root, width=400, height=400)\n",
    "photo_label.pack(pady=20)\n",
    "\n",
    "# Feedback Label\n",
    "feedback_label = tk.Label(root, text=\"Perform gestures to interact!\", font=(\"Helvetica\", 14), bg=\"#f0f0f0\")\n",
    "feedback_label.pack(pady=10)\n",
    "\n",
    "# Camera Feed Area\n",
    "camera_frame = tk.Label(root, bg=\"black\", width=500, height=500)\n",
    "camera_frame.pack(pady=10)\n",
    "\n",
    "# Functions\n",
    "def update_photo():\n",
    "    \"\"\"Update the displayed photo based on the index.\"\"\"\n",
    "    if 0 <= current_photo_index < len(photos):\n",
    "        img = ImageTk.PhotoImage(photos[current_photo_index])\n",
    "        photo_label.configure(image=img)\n",
    "        photo_label.image = img\n",
    "\n",
    "def handle_like():\n",
    "    \"\"\"Handle 'like' action.\"\"\"\n",
    "    global current_photo_index\n",
    "    liked_photos.add(current_photo_index)\n",
    "    feedback_label.config(text=\"Liked ❤️\")\n",
    "    next_photo()\n",
    "\n",
    "def handle_dislike():\n",
    "    \"\"\"Handle 'dislike' action.\"\"\"\n",
    "    global current_photo_index\n",
    "    disliked_photos.add(current_photo_index)\n",
    "    feedback_label.config(text=\"Disliked 👎\")\n",
    "    next_photo()\n",
    "\n",
    "def next_photo():\n",
    "    \"\"\"Go to the next photo.\"\"\"\n",
    "    global current_photo_index\n",
    "    current_photo_index += 1\n",
    "    if current_photo_index >= len(photos):\n",
    "        current_photo_index = 0  # Loop back to the start\n",
    "    update_photo()\n",
    "\n",
    "def scroll(direction):\n",
    "    \"\"\"Scroll through the photos.\"\"\"\n",
    "    global current_photo_index\n",
    "    if direction == \"up\" and current_photo_index > 0:\n",
    "        current_photo_index -= 1\n",
    "    elif direction == \"down\" and current_photo_index < len(photos) - 1:\n",
    "        current_photo_index += 1\n",
    "    update_photo()\n",
    "\n",
    "# Gesture Detection Integration\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "def detect_gestures():\n",
    "    \"\"\"Integrate gesture detection with UI actions.\"\"\"\n",
    "    global cap, current_gesture\n",
    "\n",
    "    try:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            print(\"Failed to capture frame\")\n",
    "            # Reschedule the detection after a short delay\n",
    "            root.after(100, detect_gestures)\n",
    "            return\n",
    "\n",
    "        # Flip the frame horizontally for a mirror-like effect\n",
    "        frame = cv2.flip(frame, 1)\n",
    "\n",
    "        # Convert the frame to RGB for MediaPipe\n",
    "        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # Process the frame for hand landmarks\n",
    "        results = hands.process(frame_rgb)\n",
    "\n",
    "        if results.multi_hand_landmarks:\n",
    "            for hand_landmarks in results.multi_hand_landmarks:\n",
    "                # Draw hand landmarks\n",
    "                mp_drawing.draw_landmarks(frame, hand_landmarks, mp_hands.HAND_CONNECTIONS)\n",
    "\n",
    "                # Add cooldown mechanism to prevent rapid gesture triggers\n",
    "                current_time = time.time()\n",
    "                if current_time - last_gesture_time > COOLDOWN_PERIOD:\n",
    "                    # Detect gestures\n",
    "                    if detect_thumbs_up(hand_landmarks):\n",
    "                        handle_like()\n",
    "                    elif detect_thumbs_down(hand_landmarks):\n",
    "                        handle_dislike()\n",
    "                    elif detect_peace_sign(hand_landmarks):\n",
    "                        feedback_label.config(text=\"Photo Saved ✌️\")\n",
    "                    else:\n",
    "                        detected, direction = detect_scroll(hand_landmarks)\n",
    "                        if detected:\n",
    "                            scroll(direction)\n",
    "\n",
    "        # Convert the frame to an image for Tkinter\n",
    "        frame_image = Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "        imgtk = ImageTk.PhotoImage(image=frame_image)\n",
    "\n",
    "        # Display the camera feed in the GUI\n",
    "        camera_frame.imgtk = imgtk\n",
    "        camera_frame.configure(image=imgtk)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error in gesture detection: {e}\")\n",
    "\n",
    "    # Always reschedule the next frame update\n",
    "    root.after(10, detect_gestures)\n",
    "\n",
    "# Initialize\n",
    "update_photo()\n",
    "\n",
    "# Start Gesture Detection\n",
    "detect_gestures()\n",
    "\n",
    "# Run Tkinter Event Loop\n",
    "root.mainloop()\n",
    "\n",
    "# Release Camera\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-12-10T15:39:28.924799Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "RAjfOu8vbX9T",
    "5WqLvhGEczPc",
    "AnVjzQPedaun"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
