{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q1hJcrtQbYOs"
   },
   "source": [
    "# HAND GESTURE-BASED INTERACTION\n",
    "\n",
    "---\n",
    "\n",
    "Group members:\n",
    "*   Ada Yƒ±lmaz\n",
    "*   Ceren ≈ûahin\n",
    "*   Sima Adleyba\n",
    "*   Selen Naz G√ºrsoy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RAjfOu8vbX9T"
   },
   "source": [
    "### Installing necessary libraries and models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XUn2JcSgZ7Q7",
    "outputId": "9c342d67-09a3-467c-8af2-efcfc6585f03"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "#install mediapipe\n",
    "%pip install -q mediapipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "KtyLGHBsaCoN"
   },
   "outputs": [],
   "source": [
    "#download a model that can recognize 7 hand gestures: üëç, üëé, ‚úåÔ∏è, ‚òùÔ∏è, ‚úä, üëã, ü§ü\n",
    "!wget -q https://storage.googleapis.com/mediapipe-models/gesture_recognizer/gesture_recognizer/float16/1/gesture_recognizer.task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "j03y4pVScZr5"
   },
   "outputs": [],
   "source": [
    "#download test images from pixabay\n",
    "import urllib\n",
    "\n",
    "IMAGE_FILENAMES = ['thumbs_down.jpg', 'victory.jpg', 'thumbs_up.jpg', 'pointing_up.jpg']\n",
    "\n",
    "for name in IMAGE_FILENAMES:\n",
    "  url = f'https://storage.googleapis.com/mediapipe-tasks/gesture_recognizer/{name}'\n",
    "  urllib.request.urlretrieve(url, name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5WqLvhGEczPc"
   },
   "source": [
    "### Functions for visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-10T15:23:11.250747Z",
     "start_time": "2024-12-10T15:23:09.667380Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-10 20:13:00.651066: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import mediapipe as mp\n",
    "from mediapipe.framework.formats import landmark_pb2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-10T15:23:11.284606Z",
     "start_time": "2024-12-10T15:23:11.254421Z"
    },
    "id": "eZQdCS6uaRny"
   },
   "outputs": [],
   "source": [
    "#some functions to visualize the gesture recognition results.\n",
    "import math\n",
    "\n",
    "plt.rcParams.update({\n",
    "    'axes.spines.top': False,\n",
    "    'axes.spines.right': False,\n",
    "    'axes.spines.left': False,\n",
    "    'axes.spines.bottom': False,\n",
    "    'xtick.labelbottom': False,\n",
    "    'xtick.bottom': False,\n",
    "    'ytick.labelleft': False,\n",
    "    'ytick.left': False,\n",
    "    'xtick.labeltop': False,\n",
    "    'xtick.top': False,\n",
    "    'ytick.labelright': False,\n",
    "    'ytick.right': False\n",
    "})\n",
    "\n",
    "mp_hands = mp.solutions.hands\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_drawing_styles = mp.solutions.drawing_styles\n",
    "\n",
    "\n",
    "def display_one_image(image, title, subplot, titlesize=16):\n",
    "    \"\"\"Displays one image along with the predicted category name and score.\"\"\"\n",
    "    plt.subplot(*subplot)\n",
    "    plt.imshow(image)\n",
    "    if len(title) > 0:\n",
    "        plt.title(title, fontsize=int(titlesize), color='black', fontdict={'verticalalignment':'center'}, pad=int(titlesize/1.5))\n",
    "    return (subplot[0], subplot[1], subplot[2]+1)\n",
    "\n",
    "\n",
    "def display_batch_of_images_with_gestures_and_hand_landmarks(images, results):\n",
    "    \"\"\"Displays a batch of images with the gesture category and its score along with the hand landmarks.\"\"\"\n",
    "    # Images and labels.\n",
    "    images = [image.numpy_view() for image in images]\n",
    "    gestures = [top_gesture for (top_gesture, _) in results]\n",
    "    multi_hand_landmarks_list = [multi_hand_landmarks for (_, multi_hand_landmarks) in results]\n",
    "\n",
    "    # Auto-squaring: this will drop data that does not fit into square or square-ish rectangle.\n",
    "    rows = int(math.sqrt(len(images)))\n",
    "    cols = len(images) // rows\n",
    "\n",
    "    # Size and spacing.\n",
    "    FIGSIZE = 13.0\n",
    "    SPACING = 0.1\n",
    "    subplot=(rows,cols, 1)\n",
    "    if rows < cols:\n",
    "        plt.figure(figsize=(FIGSIZE,FIGSIZE/cols*rows))\n",
    "    else:\n",
    "        plt.figure(figsize=(FIGSIZE/rows*cols,FIGSIZE))\n",
    "\n",
    "    # Display gestures and hand landmarks.\n",
    "    for i, (image, gestures) in enumerate(zip(images[:rows*cols], gestures[:rows*cols])):\n",
    "        title = f\"{gestures.category_name} ({gestures.score:.2f})\"\n",
    "        dynamic_titlesize = FIGSIZE*SPACING/max(rows,cols) * 40 + 3\n",
    "        annotated_image = image.copy()\n",
    "\n",
    "        for hand_landmarks in multi_hand_landmarks_list[i]:\n",
    "          hand_landmarks_proto = landmark_pb2.NormalizedLandmarkList()\n",
    "          hand_landmarks_proto.landmark.extend([\n",
    "            landmark_pb2.NormalizedLandmark(x=landmark.x, y=landmark.y, z=landmark.z) for landmark in hand_landmarks\n",
    "          ])\n",
    "\n",
    "          mp_drawing.draw_landmarks(\n",
    "            annotated_image,\n",
    "            hand_landmarks_proto,\n",
    "            mp_hands.HAND_CONNECTIONS,\n",
    "            mp_drawing_styles.get_default_hand_landmarks_style(),\n",
    "            mp_drawing_styles.get_default_hand_connections_style())\n",
    "\n",
    "        subplot = display_one_image(annotated_image, title, subplot, titlesize=dynamic_titlesize)\n",
    "\n",
    "    # Layout.\n",
    "    plt.tight_layout()\n",
    "    plt.subplots_adjust(wspace=SPACING, hspace=SPACING)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AnVjzQPedaun"
   },
   "source": [
    "### Preview the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-10T15:23:11.693865Z",
     "start_time": "2024-12-10T15:23:11.266014Z"
    },
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "m9uzHARZddDK",
    "outputId": "42c11584-885e-4a08-ee4c-a81189d64573"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Displaying: thumbs_down.jpg\n",
      "Displaying: victory.jpg\n",
      "Displaying: thumbs_up.jpg\n",
      "Displaying: pointing_up.jpg\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import math\n",
    "\n",
    "DESIRED_HEIGHT = 480\n",
    "DESIRED_WIDTH = 480\n",
    "\n",
    "def resize_and_show(image, name):\n",
    "    h, w = image.shape[:2]\n",
    "    if h < w:\n",
    "        img = cv2.resize(image, (DESIRED_WIDTH, math.floor(h / (w / DESIRED_WIDTH))))\n",
    "    else:\n",
    "        img = cv2.resize(image, (math.floor(w / (h / DESIRED_HEIGHT)), DESIRED_HEIGHT))\n",
    "    \n",
    "    # Display the image in a window with a name\n",
    "    cv2.imshow(name, img)\n",
    "    cv2.waitKey(0)  # Wait for a key press to close the window\n",
    "    cv2.destroyAllWindows()  # Close the window after key press\n",
    "\n",
    "# Example usage\n",
    "images = {name: cv2.imread(name) for name in IMAGE_FILENAMES}\n",
    "\n",
    "for name, image in images.items():\n",
    "    if image is not None:\n",
    "        print(f\"Displaying: {name}\")\n",
    "        resize_and_show(image, name)\n",
    "    else:\n",
    "        print(f\"Error: Could not read image {name}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Gesture Detection Functions\n",
    "After checking how the upper ones worked, we implemented fixed, more robust versions of gesture detection functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-10T15:23:11.732729Z",
     "start_time": "2024-12-10T15:23:11.704500Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# Global variables for tracking gestures and cooldown\n",
    "\n",
    "# The currently detected gesture\n",
    "current_gesture = None\n",
    "\n",
    "# Time when the current gesture expires\n",
    "gesture_reset_time = 0\n",
    "\n",
    "# Cooldown variables for scrolling\n",
    "previous_thumb_tip = None\n",
    "previous_index_tip = None\n",
    "last_gesture_time = 0\n",
    "COOLDOWN_PERIOD = 1.5\n",
    "\n",
    "# Reset current gesture when it expires\n",
    "def reset_gesture():\n",
    "    global current_gesture, gesture_reset_time\n",
    "    if time.time() > gesture_reset_time:\n",
    "        current_gesture = None\n",
    "\n",
    "# Gesture detection functions\n",
    "def detect_peace_sign(hand_landmarks):\n",
    "    \n",
    "    # Track the time of the last detected gesture\n",
    "    global last_gesture_time\n",
    "\n",
    "    # Get landmarks\n",
    "    index_tip = hand_landmarks.landmark[mp_hands.HandLandmark.INDEX_FINGER_TIP]\n",
    "    middle_tip = hand_landmarks.landmark[mp_hands.HandLandmark.MIDDLE_FINGER_TIP]\n",
    "    ring_tip = hand_landmarks.landmark[mp_hands.HandLandmark.RING_FINGER_TIP]\n",
    "    pinky_tip = hand_landmarks.landmark[mp_hands.HandLandmark.PINKY_TIP]\n",
    "\n",
    "    index_mcp = hand_landmarks.landmark[mp_hands.HandLandmark.INDEX_FINGER_MCP]\n",
    "    middle_mcp = hand_landmarks.landmark[mp_hands.HandLandmark.MIDDLE_FINGER_MCP]\n",
    "    ring_mcp = hand_landmarks.landmark[mp_hands.HandLandmark.RING_FINGER_MCP]\n",
    "    pinky_mcp = hand_landmarks.landmark[mp_hands.HandLandmark.PINKY_MCP]\n",
    "\n",
    "    # Check that index and middle are raised above their MCPs and other MCPs\n",
    "    index_and_middle_up = (\n",
    "        (index_tip.y < index_mcp.y) and\n",
    "        (middle_tip.y < middle_mcp.y) and\n",
    "        (index_tip.y < ring_mcp.y) and \n",
    "        (index_tip.y < pinky_mcp.y) and\n",
    "        (middle_tip.y < ring_mcp.y) and \n",
    "        (middle_tip.y < pinky_mcp.y)\n",
    "    )\n",
    "\n",
    "    # Check spacing between index and middle fingers\n",
    "    index_middle_spacing = abs(index_tip.x - middle_tip.x) > 0.1\n",
    "\n",
    "    # Check that ring and pinky are down (their tips should be below their MCP joints)\n",
    "    ring_and_pinky_down = (\n",
    "        (ring_tip.y > ring_mcp.y + 0.02) and\n",
    "        (pinky_tip.y > pinky_mcp.y + 0.02)\n",
    "    )\n",
    "\n",
    "    if index_and_middle_up and index_middle_spacing and ring_and_pinky_down:\n",
    "        \n",
    "        # Update last gesture time (to apply cooldown for peace sign gesture)\n",
    "        last_gesture_time = time.time()\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "\n",
    "\n",
    "def detect_thumbs_up(hand_landmarks, margin=0.05):\n",
    "    \n",
    "    # Track the time of the last detected gesture\n",
    "    global last_gesture_time \n",
    "\n",
    "    # Get landmarks\n",
    "    index_tip = hand_landmarks.landmark[mp_hands.HandLandmark.INDEX_FINGER_TIP]\n",
    "    middle_tip = hand_landmarks.landmark[mp_hands.HandLandmark.MIDDLE_FINGER_TIP]\n",
    "    ring_tip = hand_landmarks.landmark[mp_hands.HandLandmark.RING_FINGER_TIP]\n",
    "    pinky_tip = hand_landmarks.landmark[mp_hands.HandLandmark.PINKY_TIP]\n",
    "    thumb_tip = hand_landmarks.landmark[mp_hands.HandLandmark.THUMB_TIP]\n",
    "\n",
    "    index_mcp = hand_landmarks.landmark[mp_hands.HandLandmark.INDEX_FINGER_MCP]\n",
    "    middle_mcp = hand_landmarks.landmark[mp_hands.HandLandmark.MIDDLE_FINGER_MCP]\n",
    "    ring_mcp = hand_landmarks.landmark[mp_hands.HandLandmark.RING_FINGER_MCP]\n",
    "    pinky_mcp = hand_landmarks.landmark[mp_hands.HandLandmark.PINKY_MCP]\n",
    "    thumb_mcp = hand_landmarks.landmark[mp_hands.HandLandmark.THUMB_MCP]\n",
    "    \n",
    "    thumb_base = hand_landmarks.landmark[mp_hands.HandLandmark.THUMB_CMC]\n",
    "\n",
    "    # Thumb tip should be above other fingertips\n",
    "    thumb_tip_up = ((thumb_tip.y + margin < index_tip.y) and\n",
    "                    (thumb_tip.y + margin < middle_tip.y) and\n",
    "                    (thumb_tip.y + margin < ring_tip.y) and\n",
    "                    (thumb_tip.y + margin < pinky_tip.y) and\n",
    "                    (thumb_tip.y < thumb_mcp.y))\n",
    "    \n",
    "    # Other fingers should be in order from top to bottom\n",
    "    other_fingers_ordered = ((index_mcp.y < middle_mcp.y) and\n",
    "                             (middle_mcp.y < ring_mcp.y) and\n",
    "                             (ring_mcp.y < pinky_mcp.y))\n",
    "    \n",
    "    \n",
    "    if thumb_tip_up and other_fingers_ordered:\n",
    "        \n",
    "        # Update last gesture time (to apply cooldown for thumbs-up gesture)\n",
    "        last_gesture_time = time.time()\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "\n",
    "def detect_thumbs_down(hand_landmarks, margin=0.05):\n",
    "    \n",
    "    # Track the time of the last detected gesture\n",
    "    global last_gesture_time\n",
    "\n",
    "    # Get landmarks\n",
    "    index_tip = hand_landmarks.landmark[mp_hands.HandLandmark.INDEX_FINGER_TIP]\n",
    "    middle_tip = hand_landmarks.landmark[mp_hands.HandLandmark.MIDDLE_FINGER_TIP]\n",
    "    ring_tip = hand_landmarks.landmark[mp_hands.HandLandmark.RING_FINGER_TIP]\n",
    "    pinky_tip = hand_landmarks.landmark[mp_hands.HandLandmark.PINKY_TIP]\n",
    "    thumb_tip = hand_landmarks.landmark[mp_hands.HandLandmark.THUMB_TIP]\n",
    "\n",
    "    index_mcp = hand_landmarks.landmark[mp_hands.HandLandmark.INDEX_FINGER_MCP]\n",
    "    middle_mcp = hand_landmarks.landmark[mp_hands.HandLandmark.MIDDLE_FINGER_MCP]\n",
    "    ring_mcp = hand_landmarks.landmark[mp_hands.HandLandmark.RING_FINGER_MCP]\n",
    "    pinky_mcp = hand_landmarks.landmark[mp_hands.HandLandmark.PINKY_MCP]\n",
    "\n",
    "    # Thumb tip must be lower than anything else\n",
    "    thumb_tip_down = ((thumb_tip.y > index_tip.y + margin) and\n",
    "                    (thumb_tip.y > middle_tip.y + margin) and\n",
    "                    (thumb_tip.y > ring_tip.y + margin) and\n",
    "                    (thumb_tip.y > pinky_tip.y + margin))\n",
    "    \n",
    "    # Other fingers should be in the order (from top to down) pinky > ring > middle > index finger\n",
    "    other_fingers_ordered = ((index_mcp.y > middle_mcp.y) and\n",
    "                             (middle_mcp.y > ring_mcp.y) and\n",
    "                             (ring_mcp.y > pinky_mcp.y))\n",
    "    \n",
    "    if thumb_tip_down and other_fingers_ordered:\n",
    "        \n",
    "        # Update last gesture time (to apply cooldown for thumbs-down gesture)\n",
    "        last_gesture_time = time.time()\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def detect_scroll(hand_landmarks, threshold=0.1, dominance_ratio=4.0):\n",
    "    \n",
    "    # Get previous positions and last gesture time\n",
    "    global previous_thumb_tip, previous_index_tip, last_gesture_time\n",
    "\n",
    "    # Get current positions\n",
    "    current_thumb_tip_x = hand_landmarks.landmark[mp_hands.HandLandmark.THUMB_TIP].x\n",
    "    current_thumb_tip_y = hand_landmarks.landmark[mp_hands.HandLandmark.THUMB_TIP].y\n",
    "    current_index_tip_x = hand_landmarks.landmark[mp_hands.HandLandmark.INDEX_FINGER_TIP].x\n",
    "    current_index_tip_y = hand_landmarks.landmark[mp_hands.HandLandmark.INDEX_FINGER_TIP].y\n",
    "\n",
    "    # Check for cooldown\n",
    "    current_time = time.time()\n",
    "    \n",
    "    # If last gesture happened not before cooldown, return False (no scroll)\n",
    "    if current_time - last_gesture_time < COOLDOWN_PERIOD:\n",
    "        return False, None \n",
    "\n",
    "    # Initialize previous positions if not set\n",
    "    if previous_thumb_tip is None or previous_index_tip is None:\n",
    "        previous_thumb_tip = (current_thumb_tip_x, current_thumb_tip_y)\n",
    "        previous_index_tip = (current_index_tip_x, current_index_tip_y)\n",
    "        return False, None\n",
    "\n",
    "    # Calculate location changes\n",
    "    thumb_horizontal_disp = current_thumb_tip_x - previous_thumb_tip[0]\n",
    "    thumb_vertical_disp = current_thumb_tip_y - previous_thumb_tip[1]\n",
    "    index_horizontal_disp = current_index_tip_x - previous_index_tip[0]\n",
    "    index_vertical_disp = current_index_tip_y - previous_index_tip[1]\n",
    "\n",
    "    # Average the movements of thumb and index for robustness\n",
    "    horizontal_disp = (thumb_horizontal_disp + index_horizontal_disp) / 2\n",
    "    vertical_disp = (thumb_vertical_disp + index_vertical_disp) / 2\n",
    "\n",
    "    # Determine dominant movement (we want to return only a horizontal or vertical movement)\n",
    "    horizontal_movement = abs(horizontal_disp) > threshold\n",
    "    vertical_movement = abs(vertical_disp) > threshold\n",
    "\n",
    "    # Check dominance\n",
    "    if horizontal_movement and abs(horizontal_disp) > dominance_ratio * abs(vertical_disp):\n",
    "        direction = \"right\" if horizontal_disp > 0 else \"left\"\n",
    "        dominant_axis = \"horizontal\"\n",
    "    elif vertical_movement and abs(vertical_disp) > dominance_ratio * abs(horizontal_disp):\n",
    "        direction = \"down\" if vertical_disp > 0 else \"up\"\n",
    "        dominant_axis = \"vertical\"\n",
    "    else:\n",
    "        direction = None\n",
    "        dominant_axis = None\n",
    "\n",
    "    # If there is a dominant movement\n",
    "    if dominant_axis:\n",
    "        \n",
    "        # Update positions\n",
    "        previous_thumb_tip = (current_thumb_tip_x, current_thumb_tip_y)\n",
    "        previous_index_tip = (current_index_tip_x, current_index_tip_y)\n",
    "        \n",
    "        # Update last gesture time\n",
    "        last_gesture_time = current_time \n",
    "        return True, direction\n",
    "\n",
    "    return False, None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Instagram-like Interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-10 20:14:07.323774: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1733850852.513290  252949 gl_context.cc:357] GL version: 2.1 (2.1 INTEL-22.5.10), renderer: Intel(R) Iris(TM) Plus Graphics OpenGL Engine\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "W0000 00:00:1733850852.580856  253266 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1733850852.635394  253266 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "2024-12-10 20:14:19.058 Python[7080:252949] WARNING: AVCaptureDeviceTypeExternal is deprecated for Continuity Cameras. Please use AVCaptureDeviceTypeContinuityCamera and add NSCameraUseContinuityCameraDeviceType to your Info.plist.\n",
      "W0000 00:00:1733850862.857608  253266 landmark_projection_calculator.cc:186] Using NORM_RECT without IMAGE_DIMENSIONS is only supported for the square ROI. Provide IMAGE_DIMENSIONS or use PROJECTION_MATRIX.\n"
     ]
    }
   ],
   "source": [
    "import tkinter as tk\n",
    "from PIL import Image, ImageTk\n",
    "import os\n",
    "import cv2\n",
    "import random\n",
    "import mediapipe as mp\n",
    "import time\n",
    "\n",
    "# Initialize MediaPipe Hands\n",
    "mp_hands = mp.solutions.hands\n",
    "hands = mp_hands.Hands(min_detection_confidence=0.7, min_tracking_confidence=0.7)\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "# Initialize Tkinter\n",
    "root = tk.Tk()\n",
    "root.geometry(\"1024x768\")\n",
    "root.title(\"Gesture-Controlled Instagram\")\n",
    "\n",
    "# Load Images\n",
    "photo_folder = \"Images/\"\n",
    "photo_files = [os.path.join(photo_folder, f) for f in os.listdir(photo_folder) if f.endswith((\".jpg\", \".png\"))]\n",
    "photos = [Image.open(photo).resize((400, 400)) for photo in photo_files]\n",
    "random.shuffle(photos)  # Shuffle photos for randomness\n",
    "\n",
    "# Initialize State\n",
    "current_photo_index = 0\n",
    "liked_photos = set()\n",
    "disliked_photos = set()\n",
    "saved_photos = set()\n",
    "previous_thumb_tip = None\n",
    "previous_index_tip = None\n",
    "last_scroll_time = 0\n",
    "SCROLL_COOLDOWN = 1.5  # Cooldown in seconds\n",
    "\n",
    "# Display Area\n",
    "photo_label = tk.Label(root, width=400, height=400)\n",
    "photo_label.place(x=312, y=50)  # Center the photo in the window\n",
    "\n",
    "# Feedback Label\n",
    "feedback_label = tk.Label(root, text=\"Perform gestures to interact!\", font=(\"Helvetica\", 14), bg=\"#f0f0f0\")\n",
    "feedback_label.place(x=312, y=460)\n",
    "\n",
    "# Buttons (Top Right)\n",
    "like_button = tk.Button(root, text=\"Like ‚ù§Ô∏è\", font=(\"Helvetica\", 14), command=lambda: handle_like())\n",
    "like_button.place(x=800, y=50, width=100, height=50)\n",
    "\n",
    "dislike_button = tk.Button(root, text=\"Dislike üëé\", font=(\"Helvetica\", 14), command=lambda: handle_dislike())\n",
    "dislike_button.place(x=800, y=110, width=100, height=50)\n",
    "\n",
    "save_button = tk.Button(root, text=\"Save ‚úåÔ∏è\", font=(\"Helvetica\", 14), command=lambda: handle_save())\n",
    "save_button.place(x=800, y=170, width=100, height=50)\n",
    "\n",
    "# Cursor Label\n",
    "cursor_label = tk.Label(root, text=\"‚¨§\", fg=\"red\", font=(\"Helvetica\", 20))\n",
    "cursor_label.place(x=0, y=0)\n",
    "\n",
    "# Webcam Feed Area (Center Bottom)\n",
    "webcam_frame = tk.Label(root, bg=\"black\")\n",
    "webcam_frame.place(x=312, y=500, width=400, height=200)\n",
    "\n",
    "# Legend (Top Left)\n",
    "legend = tk.Label(root, text=(\n",
    "    \"Legend:\\n\"\n",
    "    \"üëç -> Like Picture\\n\"\n",
    "    \"üëé -> Dislike Picture\\n\"\n",
    "    \"‚úåÔ∏è -> Save Picture\\n\"\n",
    "    \"‚òùÔ∏è -> Cursor\\n\"\n",
    "    \"ü§è -> Click\\n\"\n",
    "    \"üëÜ -> Scroll Right or Down (Next Picture)\\n\"\n",
    "    \"üëÜ -> Scroll Left or Up (Previous Picture)\"\n",
    "), font=(\"Helvetica\", 10), justify=\"left\", bg=\"#f0f0f0\")\n",
    "legend.place(x=20, y=50)\n",
    "\n",
    "# Functions\n",
    "def update_photo():\n",
    "    \"\"\"Update the displayed photo based on the index.\"\"\"\n",
    "    if 0 <= current_photo_index < len(photos):\n",
    "        img = ImageTk.PhotoImage(photos[current_photo_index])\n",
    "        photo_label.configure(image=img)\n",
    "        photo_label.image = img\n",
    "\n",
    "def handle_like():\n",
    "    \"\"\"Handle 'like' action.\"\"\"\n",
    "    global current_photo_index\n",
    "    liked_photos.add(current_photo_index)\n",
    "    feedback_label.config(text=\"Liked ‚ù§Ô∏è\")\n",
    "\n",
    "def handle_dislike():\n",
    "    \"\"\"Handle 'dislike' action.\"\"\"\n",
    "    global current_photo_index\n",
    "    disliked_photos.add(current_photo_index)\n",
    "    feedback_label.config(text=\"Disliked üëé\")\n",
    "\n",
    "def handle_save():\n",
    "    \"\"\"Handle 'save' action.\"\"\"\n",
    "    global current_photo_index\n",
    "    saved_photos.add(current_photo_index)\n",
    "    feedback_label.config(text=\"Saved ‚úåÔ∏è\")\n",
    "\n",
    "def scroll(direction):\n",
    "    \"\"\"Scroll through the photos.\"\"\"\n",
    "    global current_photo_index, last_scroll_time\n",
    "\n",
    "    current_time = time.time()\n",
    "    if current_time - last_scroll_time < SCROLL_COOLDOWN:\n",
    "        return\n",
    "\n",
    "    if direction in [\"up\", \"left\"] and current_photo_index > 0:\n",
    "        current_photo_index -= 1\n",
    "        feedback_label.config(text=\"Scrolled Up/Left ‚¨ÜÔ∏è‚¨ÖÔ∏è\")\n",
    "    elif direction in [\"down\", \"right\"] and current_photo_index < len(photos) - 1:\n",
    "        current_photo_index += 1\n",
    "        feedback_label.config(text=\"Scrolled Down/Right ‚¨áÔ∏è‚û°Ô∏è\")\n",
    "\n",
    "    update_photo()\n",
    "    last_scroll_time = current_time\n",
    "\n",
    "def is_click_gesture(hand_landmarks):\n",
    "    \"\"\"Detect a pinching gesture for a click.\"\"\"\n",
    "    index_tip = hand_landmarks.landmark[mp_hands.HandLandmark.INDEX_FINGER_TIP]\n",
    "    thumb_tip = hand_landmarks.landmark[mp_hands.HandLandmark.THUMB_TIP]\n",
    "\n",
    "    # Calculate distance between index tip and thumb tip\n",
    "    distance = ((index_tip.x - thumb_tip.x) ** 2 +\n",
    "                (index_tip.y - thumb_tip.y) ** 2 +\n",
    "                (index_tip.z - thumb_tip.z) ** 2) ** 0.5\n",
    "\n",
    "    return distance < 0.05\n",
    "\n",
    "# Gesture Detection Integration\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "def detect_gestures():\n",
    "    \"\"\"Detect gestures and control the interface.\"\"\"\n",
    "    global cap\n",
    "\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        root.after(100, detect_gestures)\n",
    "        return\n",
    "\n",
    "    frame = cv2.flip(frame, 1)\n",
    "    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    results = hands.process(frame_rgb)\n",
    "\n",
    "    if results.multi_hand_landmarks:\n",
    "        for hand_landmarks in results.multi_hand_landmarks:\n",
    "            mp_drawing.draw_landmarks(frame, hand_landmarks, mp_hands.HAND_CONNECTIONS)\n",
    "\n",
    "            # Cursor Control\n",
    "            index_tip = hand_landmarks.landmark[mp_hands.HandLandmark.INDEX_FINGER_TIP]\n",
    "            cursor_x = int(index_tip.x * root.winfo_width())\n",
    "            cursor_y = int(index_tip.y * root.winfo_height())\n",
    "            cursor_label.place(x=cursor_x, y=cursor_y)\n",
    "\n",
    "            # Detect Gestures\n",
    "            if detect_thumbs_up(hand_landmarks):\n",
    "                handle_like()\n",
    "            elif detect_thumbs_down(hand_landmarks):\n",
    "                handle_dislike()\n",
    "            elif detect_peace_sign(hand_landmarks):\n",
    "                handle_save()\n",
    "            elif is_click_gesture(hand_landmarks):\n",
    "                # Simulate button click\n",
    "                for widget in [like_button, dislike_button, save_button]:\n",
    "                    widget_x = widget.winfo_x()\n",
    "                    widget_y = widget.winfo_y()\n",
    "                    widget_width = widget.winfo_width()\n",
    "                    widget_height = widget.winfo_height()\n",
    "\n",
    "                    if widget_x <= cursor_x <= widget_x + widget_width and widget_y <= cursor_y <= widget_y + widget_height:\n",
    "                        widget.invoke()\n",
    "            else:\n",
    "                detected, direction = detect_scroll(hand_landmarks)\n",
    "                if detected:\n",
    "                    scroll(direction)\n",
    "\n",
    "    # Update Webcam Feed\n",
    "    aspect_ratio = frame.shape[1] / frame.shape[0]\n",
    "    resized_width = 400\n",
    "    resized_height = int(resized_width / aspect_ratio)\n",
    "    frame_resized = cv2.resize(frame_rgb, (resized_width, resized_height))\n",
    "\n",
    "    imgtk = ImageTk.PhotoImage(Image.fromarray(frame_resized))\n",
    "    webcam_frame.imgtk = imgtk\n",
    "    webcam_frame.configure(image=imgtk)\n",
    "\n",
    "    root.after(10, detect_gestures)\n",
    "\n",
    "# Start Application\n",
    "update_photo()\n",
    "detect_gestures()\n",
    "root.mainloop()\n",
    "\n",
    "# Release Camera\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "RAjfOu8vbX9T",
    "5WqLvhGEczPc",
    "AnVjzQPedaun"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
